对于矩阵转置的例子来说,trans1就比trans2的用时长,虽然二者都是一个合并访问和一个非合并访问,但是trans2中读取是非合并的,写是合并的,.GPU 内存子系统对**读**和**写**的处理不同，且现代 GPU 有专门的只读缓存（read-only data cache，例如通过 `__ldg()` 或硬件路径利用），以及 L1/L2 缓存机制：

1. **非合并的读取（non-coalesced read）通常能被硬件缓存部分缓解**：
   - 当多个线程访问的多个地址位于同一或相邻的缓存行时，缓存会把整个缓存行拉到 L1/L2，从而减少对 DRAM 的真实随机访问次数。
   - CUDA 提供 `__ldg()`（或编译器自动把常量/只读数据走只读缓存）帮助把只读数据通过 read-only cache 加速。对于只读的数据，非合并访问的惩罚能被显著弱化。
2. **非合并的写入（non-coalesced write）惩罚更严重**：
   - 写入通常不能享受只读缓存的好处（写要写回或写合并，但写合并对 strided writes 的帮助是有限的）。
   - 非合并写入导致很多小、分散的写事务，写缓冲/合并机制很难把它们有效合并成少量大事务，代价高。

**把“非合并”留给读取，比把“非合并”留给写入更可接受/代价更小**。这就解释了为什么 `transpose2`（非合并读 + 合并写）比 `transpose1`（合并读 + 非合并写）更快。